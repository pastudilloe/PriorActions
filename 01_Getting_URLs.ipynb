{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os                                            # For file and directory operations\n",
    "from selenium import webdriver                       # Core Selenium WebDriver interface\n",
    "from selenium.webdriver.common.by import By          # “By” lets us select elements by CSS, XPath, etc.\n",
    "from selenium.webdriver.chrome.service import Service # Wraps ChromeDriver in a service object\n",
    "from webdriver_manager.chrome import ChromeDriverManager  # Auto-installs the correct ChromeDriver\n",
    "import time                                          # To pause execution (time.sleep)\n",
    "import csv                                           # To read/write CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up WebDriver using WebDriver Manager\n",
    "\n",
    "service = Service(ChromeDriverManager().install())    # Download & start ChromeDriver\n",
    "driver = webdriver.Chrome(service=service)            # Launch a Chrome browser session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Navigate to the target URL\n",
    "url = \"https://documents.worldbank.org/en/publication/documents-reports/documentlist?docty_exact=Program+Document&srt=docdt&order=desc\"\n",
    "driver.get(url)                                       # Open the URL in the browser\n",
    "time.sleep(5)                                         # Wait 5 seconds for all content to load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base path where we’ll save our data\n",
    "path1 = '/Users/pastudilloe/Library/CloudStorage/Dropbox/01 CONSULTING/WB_PriorActions_Poverty'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 69\u001b[0m\n\u001b[1;32m     62\u001b[0m     next_button \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_element(\n\u001b[1;32m     63\u001b[0m         By\u001b[38;5;241m.\u001b[39mXPATH,\n\u001b[1;32m     64\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m//ul[contains(@class, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpagination\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     65\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m//li[not(contains(@class, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisabled\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m))]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     66\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m//a[.//i[contains(@class, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfa-angle-right\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)]]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     67\u001b[0m     )\n\u001b[1;32m     68\u001b[0m     next_button\u001b[38;5;241m.\u001b[39mclick()                            \u001b[38;5;66;03m# Click the “>” arrow\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m5\u001b[39m)                                  \u001b[38;5;66;03m# Allow the new page to load\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo next page found or error clicking next page:\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Scrape through all pages, gathering data into a list\n",
    "\n",
    "all_data = []                                         # Initialize an empty list to hold each document’s metadata\n",
    "\n",
    "while True:\n",
    "    # — find every document “card” on the current page\n",
    "    listings = driver.find_elements(\n",
    "        By.CSS_SELECTOR,\n",
    "        \"div.search-listing.ng-tns-c0-0.ng-star-inserted\"\n",
    "    )\n",
    "\n",
    "    for listing in listings:\n",
    "        # Prepare placeholders for each field\n",
    "        project_name = \"\"\n",
    "        link = \"\"\n",
    "        doc_type = \"\"\n",
    "        report_no = \"\"\n",
    "        doc_date = \"\"\n",
    "        disclosure_status = \"\"\n",
    "        author = \"\"\n",
    "\n",
    "        # — Extract title and link\n",
    "        try:\n",
    "            title_elem = listing.find_element(By.CSS_SELECTOR, \"h3.ng-tns-c0-0 a\")\n",
    "            project_name = title_elem.text.strip()       # Visible text of the link\n",
    "            link = title_elem.get_attribute(\"href\")      # URL behind the link\n",
    "        except Exception as e:\n",
    "            print(\"Error extracting title:\", e)\n",
    "\n",
    "        # — Extract the other fields from the “info” section\n",
    "        try:\n",
    "            info_elem = listing.find_element(By.CSS_SELECTOR, \"div.search-listing-info\")\n",
    "            spans = info_elem.find_elements(By.CSS_SELECTOR, \"span.info-list-item\")\n",
    "            for span in spans:\n",
    "                text = span.text.strip()\n",
    "                if \"Document Type:\" in text:\n",
    "                    doc_type = text.split(\"Document Type:\")[-1].strip()\n",
    "                elif \"Report No.:\" in text:\n",
    "                    report_no = text.split(\"Report No.:\")[-1].strip()\n",
    "                elif \"Document Date:\" in text:\n",
    "                    doc_date = text.split(\"Document Date:\")[-1].strip()\n",
    "                elif \"Disclosure Status:\" in text:\n",
    "                    disclosure_status = text.split(\"Disclosure Status:\")[-1].strip()\n",
    "                elif \"Author:\" in text:\n",
    "                    author = text.split(\"Author:\")[-1].strip()\n",
    "        except Exception as e:\n",
    "            print(\"Error extracting document details:\", e)\n",
    "\n",
    "        # — Add this document’s info to our master list\n",
    "        all_data.append({\n",
    "            \"Project Name\": project_name,\n",
    "            \"Link\": link,\n",
    "            \"Document Type\": doc_type,\n",
    "            \"Report No.\": report_no,\n",
    "            \"Document Date\": doc_date,\n",
    "            \"Disclosure Status\": disclosure_status,\n",
    "            \"Author\": author\n",
    "        })\n",
    "\n",
    "    # — Try to move to the next page; if there isn’t one, break out\n",
    "    try:\n",
    "        next_button = driver.find_element(\n",
    "            By.XPATH,\n",
    "            \"//ul[contains(@class, 'pagination')]\"\n",
    "            \"//li[not(contains(@class, 'disabled'))]\"\n",
    "            \"//a[.//i[contains(@class, 'fa-angle-right')]]\"\n",
    "        )\n",
    "        next_button.click()                            # Click the “>” arrow\n",
    "        time.sleep(5)                                  # Allow the new page to load\n",
    "    except Exception as e:\n",
    "        print(\"No next page found or error clicking next page:\", e)\n",
    "        break                                         # Exit the loop when pagination ends\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the folder where we’ll dump our CSV\n",
    "\n",
    "path = os.getcwd()                                   # Current working directory\n",
    "documents_dir = os.path.join(path, path1 + \"/Documents\")\n",
    "if not os.path.exists(documents_dir):\n",
    "    os.makedirs(documents_dir)                       # Create directory if it doesn’t exist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to /Users/pastudilloe/Library/CloudStorage/Dropbox/01 CONSULTING/WB_PriorActions_Poverty/Documents/world_bank_documents_urls.csv\n"
     ]
    }
   ],
   "source": [
    "# Write everything out to a CSV\n",
    "\n",
    "csv_filename = path1 + \"/Documents/world_bank_documents_urls.csv\"\n",
    "with open(csv_filename, mode=\"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    fieldnames = [\n",
    "        \"Project Name\", \"Link\", \"Document Type\", \"Report No.\",\n",
    "        \"Document Date\", \"Disclosure Status\", \"Author\"\n",
    "    ]\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "    writer.writeheader()                             # Column headers\n",
    "    writer.writerows(all_data)                       # All our scraped rows\n",
    "\n",
    "print(f\"Data saved to {csv_filename}\")               # Confirmation message\n",
    "driver.quit()                                        # Close Chrome and end the session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
